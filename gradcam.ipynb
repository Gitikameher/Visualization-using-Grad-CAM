{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n",
    "from PIL import Image\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and \n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "    \tself.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if name=='avgpool':\n",
    "                x=module(x)\n",
    "                x=torch.reshape(x, (1,512))\n",
    "            else:\n",
    "                x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputs():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_extractor = FeatureExtractor(self.model, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations, output  = self.feature_extractor(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        #output = self.model.fc(output)\n",
    "        return target_activations, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    #preprocessed_img = img.copy()[: , :, ::-1]\n",
    "    #preprocessed_img = np.float32(np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1))))\n",
    "    # create Tensor datasets\n",
    "    transform = transforms.Compose([transforms.Resize(270), transforms.CenterCrop(256), transforms.ToTensor()])\n",
    "    input=transform(img)\n",
    "    #preprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "    #preprocessed_img.unsqueeze_(0)\n",
    "    #input = Variable(preprocessed_img, requires_grad = True)\n",
    "    return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    cv2.imwrite(\"cam.jpg\", np.uint8(255 * cam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam:\n",
    "\tdef __init__(self, model, target_layer_names, use_cuda):\n",
    "\t\tself.model = model\n",
    "\t\tself.model.eval()\n",
    "\t\tself.cuda = use_cuda\n",
    "\t\tif self.cuda:\n",
    "\t\t\tself.model = model.cuda()\n",
    "\n",
    "\t\tself.extractor = ModelOutputs(self.model, target_layer_names)\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\treturn self.model(input) \n",
    "\n",
    "\tdef __call__(self, input, index = None):\n",
    "\t\tif self.cuda:\n",
    "\t\t\tfeatures, output = self.extractor(input.cuda())\n",
    "\t\telse:\n",
    "\t\t\tfeatures, output = self.extractor(input)\n",
    "\n",
    "\t\tif index == None:\n",
    "\t\t\tindex = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "\t\tone_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)\n",
    "\t\tone_hot[0][index] = 1\n",
    "\t\tone_hot = Variable(torch.from_numpy(one_hot), requires_grad = True)\n",
    "\t\tif self.cuda:\n",
    "\t\t\tone_hot = torch.sum(one_hot.cuda() * output)\n",
    "\t\telse:\n",
    "\t\t\tone_hot = torch.sum(one_hot * output)\n",
    "\n",
    "\t\t#self.model.features.zero_grad()\n",
    "\t\tself.model.fc.zero_grad()\n",
    "\t\tone_hot.backward(retain_graph=True)\n",
    "\n",
    "\t\tgrads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "\t\ttarget = features[-1]\n",
    "\t\ttarget = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "\t\tweights = np.mean(grads_val, axis = (2, 3))[0, :]\n",
    "        \n",
    "\t\tcam = np.zeros(target.shape[1 : ], dtype = np.float32)\n",
    "\n",
    "\t\tfor i, w in enumerate(weights):\n",
    "\t\t\tcam += w * target[i, :, :]\n",
    "\n",
    "\t\tcam = np.maximum(cam, 0)\n",
    "\t\tcam = cv2.resize(cam, (256,256))\n",
    "\t\tcam = cam - np.min(cam)\n",
    "\t\tcam = cam / np.max(cam)\n",
    "\t\treturn cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=torch.load(\"resnet_best\")\n",
    "cnn.to('cuda')\n",
    "grad_cam = GradCam(model = cnn, target_layer_names = [\"layer2\"], use_cuda=True)\n",
    "img = Image.open(\"../LSTM_AFDB/dwt/testdata/ecg1.png\").convert('RGB')\n",
    "input = preprocess_image(img)\n",
    "img=input.numpy().transpose(1,2,0)\n",
    "target_index = None\n",
    "mask = grad_cam(input.unsqueeze_(0), 0)\n",
    "show_cam_on_image(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
